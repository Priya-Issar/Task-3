{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_explanation_Task-3_MIDAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWw3coeNXPWxEVJK20ZrYE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priya-Issar/Task-3/blob/main/code_explanation_Task_3_MIDAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpeJinNBz8s4"
      },
      "source": [
        "##**MIDAS@IIITD Summer Internship/RA Task 2021**\n",
        "\n",
        "##Name - Priya Issar\n",
        "\n",
        "#**Task - 3** NLP \n",
        "Problem Statement - Use a given dataset(Flipkart dataset) to build a model to predict the category using description.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nltJ9FW60MXL"
      },
      "source": [
        "##**How to Run the code file**\n",
        "\n",
        "###--> on colab notebook\n",
        "\n",
        "In order to run the code open the ipynb file on Google Colaboratory\n",
        "\n",
        "link of dataset used- https://docs.google.com/spreadsheets/d/1pLv0fNE4WHokpJHUIs-FTVnmI9STgog05e658qEON0I/edit?usp=sharing\n",
        "\n",
        "1.Upload the dataset on google drive and then mount the drive to use the dataset in the given ipynb notebook\n",
        "\n",
        "2.Mount the drive\n",
        "\n",
        "3.Copy the path of the given dataset file\n",
        "\n",
        "4.write the following code in the notebook\n",
        "\n",
        "    df= pd.read_csv('Path of file') #path of file is the copied path in step 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RfakuUl0-7o"
      },
      "source": [
        "### --> on jupyter notebook\n",
        "\n",
        "1. Download the ipynb notebook and datset\n",
        "\n",
        "2. In the notebook , write the path of downloaded notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRtXsjvi1gMw"
      },
      "source": [
        "## **How to solve the given problem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeQvMZZc1o-r"
      },
      "source": [
        "**In order to solve the problem some basic steps are followed**\n",
        "\n",
        "1. Importing Libraries\n",
        "\n",
        "2. reading data from given csv file\n",
        "\n",
        "3. Preprocessing and cleaning of data\n",
        "\n",
        "4. Visualization of data\n",
        "\n",
        "5. Spliting of Training and testing Data\n",
        "\n",
        "6. Training the algorithm \n",
        "\n",
        "7. Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUa0Mqnr2Go4"
      },
      "source": [
        "## Basic Terminologies used -\n",
        "\n",
        "1. **Alogrithm** - Sets of Procedure used to create a model from data\n",
        "\n",
        "2. **Model**- A trained machine\n",
        "\n",
        "3. **Predictor Variable** - variable containing the predicted output\n",
        "\n",
        "4. **Training data** - data used bby machine to predict\n",
        "\n",
        "5. **Testing Data** - data used by machine to predict\n",
        "\n",
        "6. **Features** - Input values of data\n",
        "\n",
        "7. **Labels/target** - Output Values of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_hpimIo4yMD"
      },
      "source": [
        "## **1. Importing Libraries**\n",
        "\n",
        "In this step libraries such as pandas and nupy is imported\n",
        "\n",
        "    import pandas as pd\n",
        "    import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iONRwqly5Vw1"
      },
      "source": [
        "## **2. Preprocessing and Cleaning of data**\n",
        "\n",
        "In this step various column are removed from the table with the help of slicing , split and lambda function.\n",
        "\n",
        "As we have to predict the category of product using description feature only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbIPBjKd6zQn"
      },
      "source": [
        "## 4. **Visualization of Data**\n",
        "\n",
        "Word Cloud is a data visualization technique used for representing text data in which the size of each word indicates its frequency or importance. \n",
        "\n",
        "For generating word cloud in Python, modules needed are – matplotlib, pandas and wordcloud.\n",
        "\n",
        "    from wordcloud import WordCloud\n",
        "    im = WordCloud(width=640, height=800).generate(\",\".join([i.text for i in words]))\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    f, a = plt.subplots(figsize=(8, 12))\n",
        "    a.imshow(im, interpolation='nearest',aspect='auto')  \n",
        "    #The imshow() function in pyplot module of matplotlib library is used to display data as an image; i.e. on a 2D regular raster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bKxDfIw8Goq"
      },
      "source": [
        "## **Count Vectorizer and Tokenization**\n",
        "\n",
        "In order to use textual data for predictive modeling, the text must be parsed to remove certain words – this process is called tokenization. These words need to then be encoded as integers, or floating-point values, for use as inputs in machine learning algorithms.\n",
        "\n",
        "    from sklearn.feature_extraction.text   \n",
        "    import CountVectorizer, TfidfTransformer\n",
        "    from sklearn.svm import SVC\n",
        "    cv = CountVectorize(stop_words='english') #this will return vector\n",
        "    tf = TfidfTransformer()\n",
        "\n",
        "  Linear SVC (Support Vector Classifier) is to fit to the data you provide, returning a \"best fit\" hyperplane that divides, or categorizes, your data. From there, after getting the hyperplane, you can then feed some features to your classifier to see what the \"predicted\" class is. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38G_p_-r8ohp"
      },
      "source": [
        "##  **5.Splitting of Testing and Training data**\n",
        "\n",
        "    from sklearn.model_selection \n",
        "    import   train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ6n7y578-EC"
      },
      "source": [
        "## **6.Training the algorithm**\n",
        "\n",
        "    from sklearn.naive_bayes import algorithm MultinomialNB\n",
        "    classifier = MultinomialNB()\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "How the algorithm is working on the given data\n",
        "\n",
        "class - different types of product category\n",
        "\n",
        "Predictor Feature - description of the product given\n",
        "\n",
        "we have to predict the product category using predictive features that is description of the product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bd8n4fY7sXo"
      },
      "source": [
        "### Resources \n",
        "\n",
        "--> https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#:~:text=Transform%20a%20count%20matrix%20to,good%20use%20in%20document%20classification.\n",
        "\n",
        "-->https://www.geeksforgeeks.org/matplotlib-pyplot-imshow-in-python/\n",
        "\n",
        "-->https://towardsdatascience.com/product-classification-using-machine-learning-part-i-5a1cd0c2caf2\n",
        "\n",
        "-->https://hackernoon.com/beginners-guide-to-product-categorization-in-machine-learning-bai3tip\n",
        "\n",
        "-->https://www.kaggle.com/PromptCloudHQ/flipkart-products/code\n",
        "\n",
        "-->https://github.com/altonalexander/product-classification-and-duplication\n",
        "\n",
        "-->https://github.com/saranggupta94/otto-product-classification\n",
        "\n",
        "\n",
        "-->https://www.youtube.com/watch?v=LmT3xyTHNR0&t=110s\n",
        "\n",
        "-->https://textblob.readthedocs.io/en/dev/quickstart.html#create-a-textblob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a98bTb3zzrjY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}